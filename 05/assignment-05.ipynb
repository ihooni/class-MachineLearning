{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment-05.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1hKHQ7jV1uM0HYOkDsVGt-SJC1FjSidT_",
      "authorship_tag": "ABX9TyP3IrZnfwaG1gRvHpHiOGob"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0FgFyxr-TH0",
        "colab_type": "text"
      },
      "source": [
        "### 1. Load data from file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBzwfk5X-Tc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "DATA_PATH = './data.txt'\n",
        "\n",
        "# load data from file\n",
        "data = np.genfromtxt(DATA_PATH, delimiter=',')\n",
        "\n",
        "# separate features from labels\n",
        "X_data = data[:, 0:-1]\n",
        "Y_data = data[:, -1].reshape(-1, 1)\n",
        "\n",
        "m = len(X_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NvYeevU-pTX",
        "colab_type": "text"
      },
      "source": [
        "### 2. Define functions for logistic regression\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQLy6yUC-puz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logistic(theta, X):\n",
        "  temp_x = np.concatenate((np.ones((m, 1)), X), axis=1)\n",
        "  z = np.matmul(temp_x, theta.T)\n",
        "  Y_hat = 1 / (1 + np.exp(-z))\n",
        "  return Y_hat\n",
        "\n",
        "def objective(Y_hat, Y):\n",
        "  epsilon = 1e-8\n",
        "  return (-1 / m) * np.sum(\n",
        "      Y * np.log(Y_hat + epsilon) + (1 - Y) * np.log(1 - Y_hat + epsilon), axis=0\n",
        "  )\n",
        "\n",
        "def gradient(X, Y_hat, Y):\n",
        "  temp_x = np.concatenate((np.ones((m, 1)), X), axis=1)\n",
        "  return (1 / m) * np.matmul((Y_hat - Y).T, temp_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHxEohAZ-zZq",
        "colab_type": "text"
      },
      "source": [
        "### 3. Learning with the gradient descent algorithm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1CymY-f-z_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "theta = np.zeros((1, X_data.shape[1] + 1))\n",
        "lr = 0.001\n",
        "epoch_count = 20000\n",
        "\n",
        "history = {\n",
        "    'theta': np.zeros((epoch_count, theta.shape[1])),\n",
        "    'train_err': np.zeros(epoch_count)\n",
        "}\n",
        "\n",
        "for epoch in range(epoch_count):\n",
        "  # calculate training error\n",
        "  Y_hat = logistic(theta, X_data)\n",
        "  train_err = objective(Y_hat, Y_data)\n",
        "\n",
        "  # log history\n",
        "  history['theta'][epoch] = np.squeeze(theta)\n",
        "  history['train_err'][epoch] = train_err\n",
        "\n",
        "  # gradient descent\n",
        "  grad_theta = gradient(X_data, Y_hat, Y_data)\n",
        "  theta -= lr * grad_theta"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}