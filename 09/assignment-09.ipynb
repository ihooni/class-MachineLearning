{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment-09.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1iNU8ch9mKV3T6TaEfJaxhdscDt3r1zmy",
      "authorship_tag": "ABX9TyNBweb/CztoYGWEprADdYI7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFNiArrrIqeB",
        "colab_type": "text"
      },
      "source": [
        "## 1. Load data from file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jeegyep8I4Eq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "DATA_PATH = './mnist.csv'\n",
        "SIZE_ROW = 28\n",
        "SIZE_COL = 28\n",
        "\n",
        "# load data from file\n",
        "data = np.genfromtxt(DATA_PATH, delimiter=',')\n",
        "\n",
        "# separate pixel values from labels\n",
        "X_raw = data[:, 1:]\n",
        "Y_raw = data[:, 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q0HjcTFK0I-",
        "colab_type": "text"
      },
      "source": [
        "## 2. Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWKO3IZvK1vW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize X data\n",
        "X_data = (X_raw - np.min(X_raw)) / (np.max(X_raw) - np.min(X_raw))\n",
        "\n",
        "# one-hot encoding Y data\n",
        "Y_data = Y_raw.astype('int')\n",
        "Y_data = np.eye(np.unique(Y_data).shape[0])[Y_data]\n",
        "\n",
        "# train data\n",
        "X_train = X_data[:6000]\n",
        "Y_train = Y_data[:6000]\n",
        "\n",
        "# test data\n",
        "X_test = X_data[6000:]\n",
        "Y_test = Y_data[6000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea6l82EsMMi-",
        "colab_type": "text"
      },
      "source": [
        "## 3. Define model and functions for learning neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC4VmWQwMOsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_weights(fan_in, fan_out):\n",
        "    return np.sqrt(1 / fan_in) * np.random.randn(fan_out, fan_in)\n",
        "\n",
        "def activation(z):\n",
        "  return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def objective(Y_pred, Y):\n",
        "  epsilon = 1e-8\n",
        "  return (-1 / Y.shape[0]) * np.sum(\n",
        "      Y * np.log(Y_pred + epsilon) + (1 - Y) * np.log(1 - Y_pred + epsilon)\n",
        "  )\n",
        "\n",
        "def accuracy(Y_pred, Y):\n",
        "  answer_Y_pred = np.argmax(Y_pred, axis=1)\n",
        "  answer_Y = np.argmax(Y, axis=1)\n",
        "  return np.mean(answer_Y_pred == answer_Y)\n",
        "\n",
        "\n",
        "class ThreeLayerNN:\n",
        "  def __init__(self, input_size, hidden1_size, hidden2_size, output_size):\n",
        "    self.params = dict()\n",
        "    self.forwards = dict()\n",
        "    self.grads = dict()\n",
        "\n",
        "    self.params['w1'] = initialize_weights(input_size, hidden1_size)\n",
        "    self.params['b1'] = np.zeros((1, hidden1_size))\n",
        "\n",
        "    self.params['w2'] = initialize_weights(hidden1_size, hidden2_size)\n",
        "    self.params['b2'] = np.zeros((1, hidden2_size))\n",
        "\n",
        "    self.params['w3'] = initialize_weights(hidden2_size, output_size)\n",
        "    self.params['b3'] = np.zeors((1, output_size))\n",
        "    \n",
        "  def forward(self, X):\n",
        "    w1, w2, w3 = self.params['w1'], self.params['w2'], self.params['w3']\n",
        "    b1, b2, b3 = self.params['b1'], self.params['b2'], self.params['b3']\n",
        "\n",
        "    forward_results = dict()\n",
        "\n",
        "    forward_results['z1'] = np.matmul(X, w1.T) + b1\n",
        "    forward_results['a1'] = activation(z1)\n",
        "\n",
        "    forward_results['z2'] = np.matmul(a1, w2.T) + b2\n",
        "    forward_results['a2'] = activation(z2)\n",
        "\n",
        "    forward_results['z3'] = np.matmul(a2, w3.T) + b3\n",
        "    forward_results['a3'] = activation(z3)\n",
        "\n",
        "    return forward_results\n",
        "\n",
        "  def backward(self, X, Y, forward_results):\n",
        "    w1, w2, w3 = self.params['w1'], self.params['w2'], self.params['w3']\n",
        "    b1, b2, b3 = self.params['b1'], self.params['b2'], self.params['b3']\n",
        "\n",
        "    z1, z2, z3 = forward_results['z1'], forward_results['z2'], forward_results['z3']\n",
        "    a1, a2, a3 = forward_results['a1'], forward_results['a2'], forward_results['a3']\n",
        "\n",
        "    dz3 = (a3 - Y) / X.shape[0]\n",
        "\n",
        "    da2 = np.matmul(dz3, w3)\n",
        "    dz2 = a2 * (1 - a2) * da2\n",
        "\n",
        "    da1 = np.matmul(dz2, w2)\n",
        "    dz1 = a1 * (1 - a1) * da1\n",
        "\n",
        "    self.grads['w3'] = np.matmul(dz3.T, a2)\n",
        "    self.grads['b3'] = np.sum(dz3, axis=0).reshape(1, -1)\n",
        "\n",
        "    self.grads['w2'] = np.matmul(dz2.T, a1)\n",
        "    self.grads['b2'] = np.sum(dz2, axis=0).reshape(1, -1)\n",
        "\n",
        "    self.grads['w1'] = np.matmul(dz1.T, X)\n",
        "    self.grads['b1'] = np.sum(dz1, axis=0).reshape(1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsx_sUiGp5o1",
        "colab_type": "text"
      },
      "source": [
        "## 4. Learning with the gradient descent algorithm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26S5TbRrp8uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.5\n",
        "epoch_count = 20000\n",
        "nn = ThreeLayerNN(784, 196, 49, 10)\n",
        "\n",
        "history = {\n",
        "    'train_loss': [],\n",
        "    'test_loss': [],\n",
        "    'train_acc': [],\n",
        "    'test_acc': []\n",
        "}\n",
        "\n",
        "for epoch in range(epoch_count):\n",
        "  # forward propagation using train data\n",
        "  train_forward_results = nn.forward(X_train)\n",
        "\n",
        "  # calculate training loss and accuracy\n",
        "  Y_train_pred = train_forward_results['a3']\n",
        "  train_loss = objective(Y_train_pred, Y_train)\n",
        "  train_acc = accuracy(Y_train_pred, Y_train)\n",
        "\n",
        "  # forward propagation using test data\n",
        "  test_forward_results = nn.forward(X_test)\n",
        "\n",
        "  # calculate testing loss and accuracy\n",
        "  Y_test_pred = test_forward_results['a3']\n",
        "  test_loss = objective(Y_test_pred, Y_test)\n",
        "  test_acc = accuracy(Y_test_pred, Y_test)\n",
        "\n",
        "  # log history\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['test_loss'].append(test_loss)\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['test_acc'].append(test_acc)\n",
        "\n",
        "  # gradient descent\n",
        "  nn.backward(X_train, Y_train, train_forward_results)\n",
        "  for key in nn.params.keys():\n",
        "    nn.params[key] -= lr * nn.grads[key]\n",
        "\n",
        "# convert list to numpy array\n",
        "for key in history.keys():\n",
        "  history[key] = np.array(history[key])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}